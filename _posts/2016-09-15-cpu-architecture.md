---

layout: post
title:  "现代微处理器架构"
date:   2016-09-15 10:20:10
categories: others
tags: 处理器架构 流水线 分支预测

---

* content
{:toc}

### 前言

本篇文章是翻译于：

[Modern Microprocessors A 90-Minute Guide!](http://www.lighterra.com/papers/modernmicroprocessors)

以前在学校读过《计算机体系结构嵌入式方法》这本书，对CPU的体系结构有了一个比较清晰的了解，
然后偶然在网上看到这篇博文瞬间觉得简直就是这本书的一个全面总结，遂想把他翻译出来，就当这本书的读书笔记吧！

## 现代微处理器架构

__警告：本文章非权威，仅仅只是兴趣__

好吧，如果你是CS专业毕业的并且大学期间学过硬件相关知识，但是不了解近几年中现代处理器的设计细节。那么这篇文章正适合你。

通常你可能不知道近些年来CPU发展的几个关键技术。。。

* 流水线（超标量，OOO，VLIW，分支预测，predicated）
* 多核和同时多线程（simultaneous multi-threading -- SMT，超线程）
* SIMD向量指令（MMX/SSE/AVX, AltiVec, NEON）
* 缓存和存储器分层结构

不要害怕，本文将带你快速了解这些概念，让你在任何时候可以像专家一样谈论顺序执行和乱序执行之间的对比，超线程，多核和缓存结构等这些话题。
但要做好心理准备--本文非常简短只会点到为止，不会介绍过多细节。让我们正式开始吧。。。

### 不仅仅是频率

首先必须搞清楚的第一个问题是时钟频率和处理器性能之间的区别。他们是不一样的，先来看看几年前的处理器的性能和频率（上世纪90年代末）：

频率|型号|SPECint95|SPECfp95
---|---
195 MHz |MIPS R10000|	11.0	 17.0
400 MHz	|Alpha 21164|	12.3	 17.2
300 MHz	|UltraSPARC	|   12.1	 15.5
300 MHz	|Pentium II	|   11.6	 8.8
300 MHz	|PowerPC G3	|   14.8	 11.4
135 MHz	|POWER2	    |   6.2	     17.6

表1 - 1997年左右的处理器性能

200MHz的MIPS R10000处理器、300MHz的UltraSPARC处理器和400MHz的Alpha 21164处理器之间的频率都不一样但是在运行大多数程序时的速度是一样的。
300MHz的Pentium II处理器在大多数情况下也有相同的速度，但是在处理浮点运算时的速度却只有一半。
PowerPC G3处理器的频率也是300MHz它在处理常规整型运算时比其他处理器快，但是浮点运算性能却远远低于前三名。
更极端的是IBM POWER2处理器仅仅只有135MHz的频率但是它的浮点运算性能与400HMz的Alpha 21164处理器相当，而整型运算能力却只有它的一半。

这是怎么回事？很显然这不仅仅只是因为时钟频率的不同--而是主要取决于处理器在每个时钟周期中是怎样工作的。

### 流水线和指令级并行

指令在处理器中是一个接着一个的执行对吗？虽然这很容易理解但是实际情况并不是这样的。事实上从19世纪80年代中期开始多个指令可以同时并行执行。
考虑指令是怎样执行的 -- 首先是取指，然后解码，接着在合适的功能单元中执行，最后将结果写入寄存器。根据这个方案，一个简单的处理器执行一条指令需要4个周期（CPI=4）。。。

![sequential2]({{"/css/pics/cpu_architecture/sequential2.png"}})
图1 - 顺序处理器的指令流

现代处理器将这些阶段叠加到一条流水线中，就像一条装配流水线。一条指令正在执行的同时下一条指令开始解码，下下一条指令则正在取指。。。

![pipelined2]({{"/css/pics/cpu_architecture/pipelined2.png"}})
图2 - 流水线处理器的指令流

现在处理器的每个时钟周期可以执行一条指令（CPI=1）。在完全没有改变时钟频率的情况下将处理器速度提高了4倍。还不错吧？

站在硬件的角度，流水线的每个阶段由一些组合逻辑和可能访问寄存器组或者某种形式的高速缓存组成。流水线的每个阶段通过锁存器分开。
一个共同的时钟信号来同步每个流水线阶段之间的锁存器，以便于所有锁存器在同一时间捕获流水线的每个阶段产生的结果。也就是说使用时钟来驱动指令在流水线上流动。

在每个时钟周期的开始，流水线中的锁存器保存着当前正在执行指令的数据和控制信息，这些信息构成了该指令输入到流水线下一阶段的逻辑电路。在一个时钟周期中，
信号通过这一阶段的组合逻辑传输到下一阶段，在时钟周期的最后每个阶段产生的输出正好被下一阶段的锁存器捕获。。。

![pipelinedmicroarch2]({{"/css/pics/cpu_architecture/pipelinedmicroarch2.png"}})
图3 - 流水线微架构

因为每条指令在流水线的执行阶段完成后产生的结果是可用的，下一条指令应该可以马上使用这个结果，而不是等到这个结果在流水线写回阶段被提交到目标寄存器后才使用。
为了实现一点，增加了被称为`旁路`的转发线路，将结果沿着流水线返回。。。

![pipelinedbypasses2]({{"/css/pics/cpu_architecture/pipelinedbypasses2.png"}})
图4 - 流水线微架构中的旁路

虽然每个流水线阶段看起来很简单，但是在`执行`这个关键阶段需要制造几组不同的逻辑（多条路径），为处理器必须有的每一种操作制作不同的功能单元。。。

![pipelinedfunctionalunits2]({{"/css/pics/cpu_architecture/pipelinedfunctionalunits2.png"}})
图5 - 流水线微架构中的更多细节

早期的RISC处理器，例如IBM的801研究原型，MIPS R2000（基于斯坦福大学的MIPS架构）和原版的SPARC（伯克利RISC的衍生项目） ，都实现了简单的5级流水线和上面介绍的一样。
在同一时期主流的80386, 68030和VAX这些CISC处理器的大部分指令还是工作在顺序执行模式 -- 因为RSIC处理器可以更加简单的实现流水线模式，因为精简指令集意味着这些指令绝大多数都是简单的寄存器到寄存器之间的操作，
不像x86, m68k 或者 VAX这些复杂指令集。结果导致20MHz的流水线模式的SPARC处理器比33MHz的顺序执行模式的386处理器运行速度还要快。
从那时开始每个处理器都实现了流水线模式，至少一定程度上的流水线化。`David Patterson`的这篇文章 [1985 CACM article](http://dl.acm.org/citation.cfm?id=214917) 对早期RISC研究项目做了一个很好的总结。

### 深度流水线 - 超级流水线

由于时钟频率限制于（其他因素除外）流水线中最长、最慢的那个阶段（译者注：一个时钟周期要大于流水线中最慢的那个阶段），逻辑门可以进一步细分每个流水线阶段，特别是最长的那个阶段，致使流水线变成更加细化的包含大量的短小阶段的超级流水线。
因此整个处理器可以运行在一个更高的时钟频率下！当然，此时每条指令需要花费更多的时钟周期来完成（时延），但是处理器仍然是每个周期完成一条指令（吞吐量），由于时钟频率更快所以处理器每秒可以执行更多的指令（实际性能）。。。

![superpipelined2]({{"/css/pics/cpu_architecture/superpipelined2.png"}})
图6 - 超级流水线处理器的指令流

Alpha架构特别喜欢这种技术，这也是为什么早期Alphas处理器拥有深度流水线在当时的时代下可以运行在如此之高的时钟频率下。
如今，现代处理器致力于限制逻辑门的数量以减少每个流水线阶段的延迟，每个流水线阶段大概12-25级门电路加上另外3-5个用于锁定自己，但是大多数处理器都有相当深度的流水线。。。

Pipeline Depth | Processors
---|---
6	|UltraSPARC T1
7	|PowerPC G4e
8	|UltraSPARC T2/T3, Cortex-A9
10	|Athlon, Scorpion
11	|Krait
12	|Pentium Pro/II/III, Athlon 64/Phenom, Apple A6
13	|Denver
14	|UltraSPARC III/IV, Core 2, Apple A7/A8
14/19	|Core i*2/i*3 Sandy/Ivy Bridge, Core i*4/i*5 Haswell/Broadwell
15	|Cortex-A15/A57
16	|PowerPC G5, Core i*1 Nehalem
18	|Bulldozer/Piledriver, Steamroller
20	|Pentium 4
31	|Pentium 4E Prescott

表2 - 常用处理器的流水线深度

通常x86处理器的流水线级数比RISCs（同时代的）的更多，因为他们需要额外的工作来解码复杂的x86指令集（以后会更多）。
UltraSPARC T1/T2/T3 Niagara处理器是深度化流水线趋势中的例外 -- UltraSPARC T1只有6级流水线，T2/T3是8级，这样做的目的是保持处理器核心尽可能的小（以后流水线级数也会更多）。

### 多发射 - 超标量

由于流水线的执行阶段是一组不同的功能单元，每个功能单元完成他们自己的任务，所以可以尝试多条指令在他们自己的功能单元中并行执行。
为了实现这一目标，取指和解码/调度阶段必须强化使他们可以并行解码多条指令，然后将他们分发到“执行资源”中去。。。

![superscalarmicroarch2]({{"/css/pics/cpu_architecture/superscalarmicroarch2.png"}})
图7 - 超标量微架构

当然，现在每个功能单元之间的流水线相互独立，他们甚至可以有不同数量的流水线级数。这可以使简单的指令更快的执行，从而减少`延迟`（我们很快会讲到）.
由于这种处理器有很多不同的流水线级数，可以很正常的想到执行整型指令的流水线通常最短，存取指令和浮点指令流水线会有少量其他的流水线阶段。
因此，一个10级流水线的处理器使用10级来执行整型指令，存取指令可能有12或者13级，浮点指令可能有14或者15级。
流水线内部和流水线之间也会有一堆旁路，但是为了简化上图中省略了旁路。

在上面的例子中，处理器可能在一个时钟周期内发射3个不同的指令 -- 例如1个整型指令，1个浮点指令和1个存取指令。甚至可以添加更多功能单元，实现处理器在每个时钟周期内可以执行2个整型指令，或者2个浮点指令，
或者目标应用程序可以最高效率运行的任何指令组合。

在一个超标量处理器中，指令流大概像是这样的。。。

![superscalar2]({{"/css/pics/cpu_architecture/superscalar2.png"}})
图8 - 超标量处理器中的指令流

这是非常棒的！现在每个时钟周期可以完成3个指令（CPI=0.33或者IPC=3，也可以写成ILP=3（instruction-level parallelism）- 指令级并行）。
处理器在每个时钟周期内可以发射，执行或者完成的指令数量称为处理器的带宽。

注意发射带宽一般小于功能单元的数量，因为不同的代码序列有不同的指令组合，我们的目标是达到每个时钟周期执行3条指令但是这些指令不可能总是1个整型指令，1个浮点指令和1个内存操作指令，因此功能单元的数量需要大于3个。

IBM POWER1处理器 - PowerPC的前代是第一个主流超标量处理器。之后大多数RISCs处理器（SuperSPARC, Alpha 21064）开始使用超标量。Intel也试图制造x86架构的超标量处理器 - Pentium处理器的原始版本 - 然而复杂的x86指令集成了一个很大的难题。

当然，处理器的深度流水线和多指令发射技术都在发展，所以超级流水线和超标量可以同时出现。。。

![superpipelinedsuperscalar2]({{"/css/pics/cpu_architecture/superpipelinedsuperscalar2.png"}})
图9 - 超流水线-超标量处理器的指令流

如今实际上每一款处理器都同时是超流水线-超标量的，所以被简称为超标量。严格的说超流水线只是表示更深级数的流水线。

现代处理器的带宽有很大差别。。。

Issue Width	| Processors
---|---
1	|UltraSPARC T1
2	|UltraSPARC T2/T3, Scorpion, Cortex-A9
3	|Pentium Pro/II/III/M, Pentium 4, Krait, Apple A6, Cortex-A15/A57
4	|UltraSPARC III/IV, PowerPC G4e
4/8	|Bulldozer/Piledriver, Steamroller
5	|PowerPC G5
6	|Athlon, Athlon 64/Phenom, Core 2, Core i*1 Nehalem, Core i*2/i*3 Sandy/Ivy Bridge, Apple A7/A8
7	|Denver
8	|Core i*4/i*5 Haswell/Broadwell

表3 - 通用处理器的发射带宽

每款处理器的功能单元的实际数量和类型取决于目标市场。某些处理器的浮点运算资源更多（IBM的POWER处理器产品线），其他处理器则更加倾向于整型运算（Pentium Pro/II/III/M），
还有一些处理器则将资源投向SIMD向量指令（PowerPC G4/G4e），然而大多数处理器尽量使各种资源均衡。

### 显示并行 - VLIW

在那些不需要考虑向后兼容问题的使用场景中，使指令集本身被设计为可以并行执行的显示分组指令（explicitly group instructions）成为可能。
这种方法消除了在调度阶段需要的复杂的依赖性检查逻辑，可以使处理器的设计更加简单，体积更小，更容易的提高时钟频率（至少在理论上）。

在这种类型的处理器中，`指令`是指被分组过的更小的子指令集合，因此指令本身是非常长的，通常是128比特或者更多。所以`VLIW`的意思是超长指令字（very long instruction word）。
每条指令包含了多个并行操作的信息。

除了解码/调度阶段更加简单（因为只需要解码/调度每个组中的子指令）外VLIW处理器的指令流和超标量的很像。。。

![vliw2]({{"/css/pics/cpu_architecture/vliw2.png"}})
图10 - VLIW处理器的指令流

除了简化调度逻辑外VLIW处理器和超标量处理器非常相似。尤其是站在编译器的角度来看（下面会讲到）。

值得注意的是，大多数VLIW的指令相互之间没有关联。这意味着指令之间不需要依赖性检查，并且当缓存未命中时没有办法停止来指令的执行只能停止整个CPU。因此编译器需要在依赖指令之间插入适当数量的时钟周期的间隔时间，
如果没有其他指令来填充这个间隔时间，甚至会使用`nops`（无操作，空指令）指令来填充。这使得编译器更加复杂化，因为在超标量处理器上通常是在运行时刻做这些操作的，为了节约处理器宝贵的片上资源编译器中这些额外的代码都是最小化的。

非VLIW设计仍然是商业领域内的主流CPUs，但是Intel的IA-64架构（应用于安腾处理器系列产品中）曾经试图取代x86架构。Intel将IA-64称为`EPIC`设计，意思是“显示并行指令计算”（explicitly parallel instruction computing），但是实际上就是VLIW的基础上加上智能分组（保证长期兼容性）和分支预测功能。
图形处理器（GPUs）中的可编程着色器有时候采用VLIW设计，同时还有很多数字信号处理器（DSPs），也有Transmeta（全美达）这样的公司使用VLIW。

### 指令依赖和延迟

流水线和超标量能够发展多久？如果5级流水线可以快5倍，为什么不制作20级流水线？如果超标量每秒发射4条指令可以完美运行，为什么不发展为每秒发射8条指令？更进一步，为什么不制作一款50级流水线并且每个时钟周期发射20条指令的CPU？

好吧，考虑下面俩条语句。。。

```c

a = b * c;
d = a + 1;

```

第二条语句依赖于第一条语句的结果 -- 处理器不可能在第一条语句执行完产生结果之前就执行第二条语句。这是一个非常严重的问题，因为相互依赖的指令不能并行执行。因此多发射在这种情况下也不能使用。

如果第一条语句是一个简单的整型加法运算对于单发射的流水线处理器是可行的，因为整型加法的运算非常快，第一条语句的结果可以及时反馈（使用旁路）给下一条语句。但是对于多发射的情况，则会浪费几个周期来完成这个运算，因为没有办法在一个时钟周期的间隔内将第一条指令的结果传送给已经到达执行阶段的第二条指令。
所以处理器需要停止执行第二条指令直到第一条指令的结果可用，通过在流水线中插入气泡（bubble）来实现停顿。

当一条指令从执行阶段到它的结果可以被其他指令使用这之间间隔的时钟周期数量称为指令的延迟（latency）。流水线越深、级数越多指令延迟就越长。所以一个很长的流水线并不会比一个短流水线的效率高，由于指令之间的依赖会使越长的流水线中填充越多的气泡（bubble）。

站在编译器的角度来看，现代处理器的典型延迟时间范围从1个时钟周期（整型操作）到3-6个时钟周期（浮点加法、乘法运算可能相同或者稍微长一点），在到十几个时钟周期（整型除法）。

对于内存加载指令来说延迟是一个非常麻烦的问题，部分原因是他们通常发生在代码序列的早期，导致很难使用有效的指令来填充延迟，另外一个重要的原因是他们都是不可预测的 - 加载延迟的时间很大程度上取决于访问缓存是否命中（我们稍后很提到缓存）。

注：在相关但意义不一样的地方使用"latency"（延迟）这个词可能会造成误解。我们这里谈论的延迟是从编译器的角度来说的，但是对于硬件工程师来说延迟的意思是一条指令在流水线中执行完成所需要时钟周期（流水线级数）。所以硬件工程师会说一个简单的整型流水线的延迟是5但是吞吐量是1。
然而从编译器的角度来说他们的延迟是1因为他们的结果可以在下一个周期中使用。编译器的角度更加通用并且甚至在硬件手册中也会使用。

### 分支和分支预测

流水线的另外一个关键问题是分支。考虑下面这段代码。。。

```c

if (a > 7) {
    b = c;
} else {
    b = d;
}

```

这段代码类似下面这种形式：

```c

  cmp a, 7    ; a > 7 ?
    ble L1
    mov c, b    ; b = c
    br L2
L1: mov d, b    ; b = d
L2: ...

```

现在想象流水线处理器执行这段代码。当第二行的条件分支在流水线中到了执行阶段，处理器应该已经取指并解码了下一条指令，但是应该是那一条指令？他是取指并解码`if`分支（3，4行）还是`else`分支（第5行）？
一直到条件分支到达执行阶段才能知道答案，但是在一个深度流水线处理器中可能需要间隔几个时钟周期。并且它不能只是等待--处理器平均会在每6条指令中遇到一个分支，如果在每个分支下都等待几个时钟周期那么在一开始为了提高性能而使用流水线就没有可能。

因此处理器必须做出猜测。处理器会在执行这些指令的开始猜测和推测取指的路径。当然他不会实际提交（写回）这些指令的执行结果直到分支的结果已知。糟糕的是如果猜测错误这些指令不得不取消而这些时钟周期将会被浪费。但是如果猜测正确则处理器可以继续全速运行。

问题的关键是处理器应该怎样进行猜测。两种方案可供选择。第一，编译器应该可以标记这个分支来告诉处理器执行哪一条路径，这被称为静态分支预测。理想的情况是指令中有一个位来标记预测分支，但是对于早期的架构没有这个选项，
所以可以使用一个约定来实现，例如将预测会被执行的分支放在后面，不会被执行的分支放在前面。更重要的是这种方法要求编译器足够智能够正确预测，对于循环来说这很容易但是对于其他分支来说就可能非常困难了。

另一种方法是处理器在运行时刻做出判断。通常使用一个片上分支预测表来实现，表中保存着最近执行过的分支的地址并且用一位来标记每个分支在上一次运行中是否被执行。实际上，大多数处理器使用两位来标记，这样可以避免单个偶然事件的发生不会影响预测结果（尤其是在循环边缘的）。
当然这个动态分支预测表需要占用处理器片上的宝贵资源但是分支预测是如此重要所以这点资源是值得的

不幸的是即使是最好的分支预测技术有时也会预测错误，从而导致一个深度流水线上的很多指令都要被取消，这被称为分支预测惩罚。Pentium Pro/II/III处理器是一个很好的例子 -- 它有12级流水线因此错误预测惩罚是10-15个时钟周期。
即使使用非常智能的动态分支预测器其正确率可以达到惊人的90%，但是由于高昂的分支预测惩罚也会使Pentium Pro/II/III处理器浪费掉30%的性能。换句话说Pentium Pro/II/III处理器三分之一的时间都在做没有用的工作,而是再说“哎呀，走错路了”.

现代处理器致力于投入更多的硬件资源到分支预测上，试图提高预测的准确率以减少错误预测惩罚的开销。很多记录每一个分支的方向并不是孤立的，而是由两个分支的执行情况来决定的，这被称为两级自适应预测器。有些处理器保存了一个全局的分支执行历史，而不是每个单独分支的分散的执行记录，以试图检测分支之间的任何关联性即使他们在代码中相隔较远。
这被称为`gshare`或者 `gselect` 预测器。现代最先进的处理器通常实现了多个分支预测器然后在他们之间选择那个看起来在每个单独分支上预测最精准的一个。

然而即使是最先进的处理器使用了做好的、最智能的分支预测器也只能将正确率提升到95%，仍然会由于预测错误而失去相当一部分的性能。规则非常简单 -- 流水线太深则会收益减少，因为流水线越深你就必须预测越多的分支，所以错误的可能性也越大，并且错误预测惩罚也越大。

### 消除和预测分支

条件分支是一个大问题所以如果能完全去掉他们那就太好了。但是不可能在编程语言中取消`if`语句，所以怎样才能消除分支了？答案就在一些分支的使用方法中。

再次回到上面的例子中，5条指令中有两个分支，其中一个是无条件转移分支。如果可以给`mov`指令做一个标记告诉他们只在某个条件下执行，则代码可以简化为：

```c
cmp a, 7       ; a > 7 ?
mov c, b       ; b = c
cmovle d, b    ; if le, then b = d
```

这里引入了一条新的指令`cmovle` -- “如果小于或等于则移动”。这条指令会正常执行但是只有在条件为真的时候才会提交执行结果。这种指令称为谓词指令，因为它的执行被一个谓词控制（判断真/假）。

使用这种新的谓词移动指令，代码中的两条消耗较大的分支指令都可以被移除。另外聪明的做法是总是首先执行`mov`指令然后如果需要则覆盖`mov`指令的结果。同时也提高了代码的并行度 -- 第1、2行的代码现在可以并行执行。结果是提速了50%（2个周期而不是3个）。
更重要的是消除了分支预测错误时的巨大的错误预测惩罚。

当然如果`if`和`else`语句中的代码块非常大，则使用谓词会比使用分支执行更多的指令，因为处理器会将两条路径上的代码都执行一遍。通过多执行几条指令以消除分支是否值得这是一个棘手的决定--如果代码块很小或者很大则这个决定很容易，
但是对于那些中等大小的代码块则需要负责的权衡，这种情况在优化时必须考虑到。

Alpha架构在一开始就有条件移动指令。MIPS, SPARC 和 x86是后面在加上的。在IA-64中Intel尽力将几乎所有指令变成谓词指令，试图显著减少循环内部中的分支问题尤其是那些不可预测的分支，例如编译器和OS内核中的分支。
有趣的是许多手机和平板中使用的ARM架构是第一种全谓词指令集的架构。更有趣的是早期的ARM处理器只有很短的流水线因此它的错误预测惩罚相对较小。

### 指令调度，寄存器重命名和OOO

如果是分支并且指令延迟很长则会在流水线中产生气泡，但是这些空周期应该可以被用来做其他工作。为了实现这一点程序中的指令必须重新排序，当一条指令在等待时可以执行其他指令。例如在上面的那个乘法例子中可以在两条语句之间插入程序中其他的语句。

有两种方法可以实现指令调度，一种方法是在运行时刻在硬件中对指令重新排序。在处理器中实现动态指令调度（重新排序）意味着处理器的指令调度逻辑必须增强，使他可以在指令组中查找并乱序分发指令使处理器功能单元可以得到最好的利用。
不出所料这就是所谓的乱序执行，或者简称为OOO（优势也被写为OoO或者OOE）。

如果处理器打算乱序执行指令，则它需要记住这些指令之间的依赖性。通过使用一组重命名寄存器而不去处理原始架构定义的寄存器可以很容易实现这个目的。
例如将寄存器中的值存储到内存中，接着加载内存中的其他值到相同名字的寄存器中表示不同的值但是不需要加载到同一个物理寄存器中。更进一步说，如果这些不同的指令映射到不同的物理寄存器中则他们可以并行执行，这就是实现乱序执行的方法。
因此处理器必须时刻保存着指令在执行过程中和指令所使用的物理寄存器之间的映射。这个过程叫做寄存器重命名。一个额外的好处是可以利用更多的寄存器在代码中提取更多的可以并行执行的指令。

所有的这些依赖分析、寄存器重命名和乱序执行都需要在处理器中增加大量的复杂逻辑，使处理器的设计更加困难、芯片面积更大、功率更大。
这些额外的处理逻辑特别耗电因为这些晶体管总是处于工作状态，不像处理器中的功能单元至少有时候可以处于闲置状态（甚至可能关闭）。
但是乱序执行的优势在于软件不需要重新编译就可以获得一定的性能提升，但通常不是所有软件。

另一种一劳永逸的方法是通过编译器来重新安排指令的执行顺序。这叫做静态或者编译时刻指令调度。依赖于编译器的指令安排使得重新排序的指令流可以简单有序的被送入处理器的多发射器中。这样就避免了处理器中为了实现乱序执行而增加的复杂逻辑，使得处理器设计简单、功率变小并且芯片面积更小，
这就意味着更多的处理核心或者缓存可以放在相同面积大小的芯片中。

使用编译器实现的方法比硬件实现还有另外一个优点是 -- 他可以看到程序执行时的更底层细节，并且可以推测分支的多条路径而不只是一条，这对于分支预测来说很重要。但是不能对编译器抱有太大希望，因为它不可能总是使得一切完美。
如果没有支持乱序执行的硬件，当编译器预测失败例如缓存未命中则会导致流水线停滞。

大多数早期超标量处理器都是循序执行的设计（SuperSPARC, hyperSPARC, UltraSPARC, Alpha 21064 & 21164, 早期的Pentium）。早期乱序设计的处理器有MIPS R10000, Alpha 21264 和基本上整个POWER/PowerPC产品线。如今几乎所有高性能处理器都是乱序设计，但是有几个明显的例外UltraSPARC III/IV, POWER6 和 Denver。
大多数低功率，低性能的处理器例如Cortex-A7/A53和Atom都是顺序设计的因为乱序逻辑消耗了太多的电能但是性能的提升却很有限。

### 能量墙和ILP墙